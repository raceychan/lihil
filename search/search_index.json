{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"NOTE: We have refactored our docs site and migrated from lihil/lihil (You are here) to lihil, This site is deprecated and won't have the latest updates","text":"<p>Lihil /\u02c8li\u02d0ha\u026al/ \u2014 a performant, productive, and professional web framework with a vision:</p> <p>Making Python the mainstream programming language for web development.</p> <p> </p> <p>Lihil is</p> <ul> <li> <p>Performant: 50%-100% faster than ASGI frameworks offering similar functionalities, even more with its own server. see benchmarks, web-frameworks-benchmark</p> </li> <li> <p>Productive: Lihil includes essential middleware for enterprise development\u2014such as authentication, authorization, throttling, and event publishing\u2014enabling productivity from day one. Its ergonomic API, strong typing support, and built-in solutions for common challenges\u2014along with developer-friendly features like OpenAPI documentation generation\u2014empower you to build applications quickly without compromising on flexibility or extensibility.</p> </li> <li> <p>professional: Start small, move fast, achieve great, Lihil follows industry standards (RFC 9110, RFC 9457, etc.) and best practices like event-driven architecture (EDA) and service choreography to help you deliver robust, scalable solutions with confidence.</p> </li> </ul>"},{"location":"#uv","title":"uv","text":"<p>if you want to install this project with uv</p> <p>uv install guide</p> <ol> <li>init your web project with <code>project_name</code></li> </ol> <pre><code>uv init project_name\n</code></pre> <ol> <li>install lihil via uv, this will solve all dependencies for your in a dedicated venv.</li> </ol> <pre><code>uv add lihil\n</code></pre>"},{"location":"#features","title":"Features","text":""},{"location":"#low-memory-usage","title":"Low memory Usage","text":"<p>lihil is deeply optimized for memory usage, significantly reduce GC overhead, making your services more robust and resilient under load.</p>"},{"location":"#param-parsing-validation","title":"Param Parsing &amp; Validation","text":"<p>Lihil provides a high level abstraction for parsing request, validating rquest data against endpoint type hints using <code>msgspe</code>, which is extremly performant, 12x faster and 25x more memory efficient than pydantic v2.</p> <p>see benchmarks,</p> <ul> <li>Param Parsing: Automatically parse parameters from query strings, path parameters, headers, and request bodies</li> <li>Validation: Parameters are automatically converted to &amp; validated against their annotated types and constraints.</li> <li>Custom Decoders: Apply custom decoders to have the maximum control of how your param should be parsed &amp; validated.</li> </ul> <pre><code>from lihil import Payload, Header, Route, Meta, use\nfrom .service import get_user_service, UserService\n\nclass UserPayload(Payload): # memory optimized data structure that does not involve in gc.\n    user_name: Annotated[str, Meta(min_length=1)] # non-empty string with length &gt;= 1\n\nall_users = Route(\"users\")\nall_users.factory(get_user_service)\n\n# All parameters are automatically parsed and validated\n@all_users.sub(\"{user_id}\").post # POST /users/{user_id}\nasync def create_user(\n    user_id: str,                                           # from URL path\n    auth_token: Header[str, Literal[\"x-auth-token\"]],       # from request headers\n    user_data: UserPayload,                                 # from request body\n    service: UserService\n) -&gt; Resp[str, 201]: ...\n</code></pre>"},{"location":"#dependency-injection","title":"Dependency Injection","text":"<p>Lihil features a powerful dependency injection system:</p> <ul> <li>Automatic Resolution: Dependencies are automatically resolved and injected based on type hints.</li> <li>Scoped Dependencies: Support for nested, infinite levels of scoped, singleton, and transient dependencies</li> <li>Nested Dependencies: Dependencies can have their own dependencies</li> <li>Factory Support: Create dependencies using factory functions with custom configuration</li> <li>Lazy Initialization: Dependencies are only created when needed</li> </ul> <pre><code>async def get_conn(engine: Engine):\n    async with engine.connect() as conn:\n        yield conn\n\nasync def get_users(conn: AsyncConnection):\n    return await conn.execute(text(\"SELECT * FROM users\"))\n\n@Route(\"users\").get\nasync def list_users(users: Annotated[list[User], use(get_users)], is_active: bool=True):\n    return [u for u in users if u.is_active == is_active]\n</code></pre> <p>For more in-depth tutorials on DI, checkout https://lihil.cc/ididi</p>"},{"location":"#openapi-schemas","title":"OpenAPI schemas","text":"<p>Lihil automatically generates comprehensive OpenAPI documentation:</p> <ul> <li>Type-Based Schema Generation: Schemas are derived from Python type annotations</li> <li>Detailed Parameter Documentation: Documents all parameters with their sources, types, and requirements</li> <li>Response Documentation: Automatically documents response types and status codes</li> <li>Error Documentation: Includes detailed error schemas in the documentation</li> <li>Examples Support: Add examples to make your API documentation more helpful</li> </ul>"},{"location":"#exception-problem-mapping-problem-page","title":"Exception-Problem Mapping &amp; Problem Page","text":"<p>Lihil implements the RFC 7807 Problem Details standard for error reporting</p> <p>lihil maps your exception to a <code>Problem</code> and generate detailed response based on your exception.</p> <pre><code>class OutOfStockError(HTTPException[str]):\n    \"The order can't be placed because items are out of stock\"\n    __status__ = 422\n\n    def __init__(self, order: Order):\n        detail: str = f\"{order} can't be placed, because {order.items} is short in quantity\"\n        super().__init__(detail)\n</code></pre> <p>when such exception is raised from endpoint, client would receive a response like this</p> <pre><code>{\n    \"type_\": \"out-of-stock-error\",\n    \"status\": 422,\n    \"title\": \"The order can't be placed because items are out of stock\",\n    \"detail\": \"order(id=43, items=[massager], quantity=0) can't be placed, because [massager] is short in quantity\",\n    \"instance\": \"/users/ben/orders/43\"\n}\n</code></pre>"},{"location":"#builtin-auth-system","title":"Builtin Auth system","text":"<pre><code>from lihil import Payload, Route\nfrom lihil.auth.jwt import JWTAuth, JWTPayload\nfrom lihil.auth.oauth import OAuth2PasswordFlow, OAuthLoginForm\n\nme = Route(\"me\")\ntoken = Route(\"token\")\n\n\nclass UserProfile(JWTPayload):\n    __jwt_claims__ = {\"expires_in\": 300}\n\n    user_id: str = field(name=\"sub\")\n    role: Literal[\"admin\", \"user\"] = \"user\"\n\n\nclass User(Payload):\n    name: str\n    email: str\n\n\ntoken_based = OAuth2PasswordFlow(token_url=\"token\")\n\n\n@me.get(auth_scheme=token_based)\nasync def get_user(profile: JWTAuth[UserProfile]) -&gt; User:\n    assert profile.role == \"user\"\n    return User(name=\"user\", email=\"user@email.com\")\n\n@token.post\nasync def create_token(credentials: OAuthLoginForm) -&gt; JWTAuth[UserProfile]:\n    return UserProfile(user_id=\"user123\")\n</code></pre>"},{"location":"#message-system","title":"Message System","text":"<p>Lihil has built-in support for both in-process message handling</p> <p>There are three primitives for event:</p> <ol> <li>publish: asynchronous and blocking event handling that shares the same scope with caller.</li> <li>emit: non-blocking asynchrounous event hanlding, has its own scope.</li> <li>sink: a thin wrapper around external dependency for data persistence, such as message queue or database.</li> </ol> <pre><code>from lihil import Resp, Route, status\nfrom lihil.plugins.bus import Event, EventBus\nfrom lihil.plugins.testclient import LocalClient\n\n\nclass TodoCreated(Event):\n    name: str\n    content: str\n\n\nasync def listen_create(created: TodoCreated, ctx):\n    assert created.name\n    assert created.content\n\n\nasync def listen_twice(created: TodoCreated, ctx):\n    assert created.name\n    assert created.content\n\n\nbus_route = Route(\"/bus\", listeners=[listen_create, listen_twice])\n\n\n@bus_route.post\nasync def create_todo(name: str, content: str, bus: EventBus) -&gt; Resp[None, status.OK]:\n    await bus.publish(TodoCreated(name, content))\n</code></pre> <p>An event can have multiple event handlers, they will be called in sequence, config your <code>BusTerminal</code> with <code>publisher</code> then inject it to <code>Lihil</code>.</p> <ul> <li> <p>An event handler can have as many dependencies as you want, but it should at least contain two params: a sub type of <code>Event</code>, and a sub type of <code>MessageContext</code>.</p> </li> <li> <p>if a handler is registered with a parent event, it will listen to all of its sub events. for example,</p> </li> <li> <p>a handler that listens to <code>UserEvent</code>, will also be called when <code>UserCreated(UserEvent)</code>, <code>UserDeleted(UserEvent)</code> event is published/emitted.</p> </li> <li> <p>you can also publish event during event handling, to do so, declare one of your dependency as <code>EventBus</code>,</p> </li> </ul> <pre><code>async def listen_create(created: TodoCreated, _: Any, bus: EventBus):\n    if is_expired(created.created_at):\n        event = TodoExpired.from_event(created)\n        await bus.publish(event)\n</code></pre>"},{"location":"#typing-support","title":"typing support","text":"<p>typing plays a significant role in the world of <code>lihil</code>, lihil combines generics, function overriding, paramspec and other advanced typing features to give you the best typing support possible.</p> <p>with its dedicated, insanely detailed typing support, lihil will give you something to smile about.</p> <p></p> <p></p>"},{"location":"#versioning","title":"versioning","text":"<p>lihil follows semantic versioning, where a version in x.y.z represents:</p> <ul> <li>x: major, breaking change</li> <li>y: minor, feature updates</li> <li>z: patch, bug fixes, typing updates</li> </ul> <p>v1.0.0 will be the first stable major version.</p>"},{"location":"advanced/","title":"Advanced Usage","text":""},{"location":"advanced/#authentification","title":"Authentification","text":""},{"location":"advanced/#auth-header","title":"Auth header","text":""},{"location":"advanced/#json-web-token","title":"Json Web Token","text":""},{"location":"advanced/#oauth","title":"OAuth","text":""},{"location":"advanced/#plugins-param-processor","title":"Plugins &amp; Param Processor","text":""},{"location":"advanced/#plugins","title":"Plugins","text":""},{"location":"advanced/#initialization","title":"Initialization","text":"<ul> <li>init at lifespan</li> </ul> <pre><code>from lihil import Graph\n\nasync def lifespan(app: Lihil):\n    async with YourPlugin() as up:\n        app.graph.register_singleton(up)\n        yield\n\nlhl = LIhil(lifespan=lifespan)\n</code></pre> <p>use it anywhere with DI</p> <ul> <li>init at middleware</li> </ul> <p>plugin can be initialized and injected into middleware, middleware can be bind to different route, for example <code>Throttle</code></p> <pre><code># pseudo code\nclass ThrottleMiddleware:\n    def __init__(self, app: Ignore[ASGIApp], redis: Redis):\n        self.app = app\n        self.redis = redis\n\n    async def __call__(self, app):\n        await self.redis.run_throttle_script\n        await self.app\n</code></pre> <p>lihil accepts a factory to build your middleware, so that you can use di inside the factory, and it will perserve typing info as well. Anything callable that requires only one positonal argument can be a factory, which include most ASGI middleware classes.</p> <pre><code>lihil.add_middleware(lambda app: app.graph.resolve(ThrottleMiddleware))\n</code></pre> <ul> <li>Use it at your endpoints</li> </ul> <pre><code>async def create_user(user_name: str, plugin: YourPlugin): ...\n</code></pre>"},{"location":"benchmark/","title":"Benchmark","text":"<ul> <li>lihil's dedicated benchmark repo</li> </ul> <p>lhl_benchmark</p> <p>Tests are deliberately made to be easily reproducible.</p> <ul> <li>third-party benchmarks</li> </ul> <p>web-frameworks-benchmark</p>"},{"location":"contribute/","title":"Contribute","text":"<p>No contribution is trivial and every contribution is appreciated, however, we do have different focus &amp; goals in different stage of this project</p>"},{"location":"contribute/#roadmap","title":"RoadMap","text":""},{"location":"contribute/#version-01x-feature-parity","title":"version 0.1.x: Feature Parity","text":"<ul> <li> <p>Feature Parity: we should offer core functionalities of a web framework ASAP, similar to what fastapi is offering right now. Given both fastapi and lihil uses starlette, this should not take too much effort.</p> </li> <li> <p>Correctness: We should have a preliminary understanding of lihil's capabilities\u2014knowing what should be supported and what shouldn't. This allows us to distinguish between correct and incorrect usage by users.</p> </li> <li> <p>Test Coverage: There's no such thing as too many tests. For every patch, we should maintain at least 99% test coverage, and 100% for the last patch of 0.1.x. For core code, 100% coverage is just the baseline\u2014we should continuously add test cases to ensure reliability.</p> </li> </ul> <p>Based on the above points, in version v0.1.x, we welcome contributions in the following areas:</p> <ul> <li> <p>Documentation: Fix and expand the documentation. Since lihil is actively evolving, features may change or extend, and we need to keep the documentation up to date.</p> </li> <li> <p>Testing: Contribute both successful and failing test cases to improve coverage and reliability.</p> </li> <li> <p>Feature Requests: We are open to discussions on what features lihil should have or how existing features can be improved. However, at this stage, we take a conservative approach to adding new features unless there is a significant advantage.</p> </li> </ul>"},{"location":"contribute/#version-02x-cool-stuff","title":"version 0.2.x Cool Stuff","text":"<ul> <li>Out-of-process event system (RabbitMQ, Kafka, etc.).</li> <li>A highly performant schema-based query builder based on asyncpg</li> <li>Local command handler(http rpc) and remote command handler (gRPC)</li> <li>More middleware and official plugins (e.g., throttling, caching, auth).</li> </ul>"},{"location":"contribute/#version-03x-performance-boost","title":"version 0.3.x Performance boost","text":""},{"location":"contribute/#version-04x-onwards","title":"version 0.4.x onwards","text":"<ul> <li>implementing requested feature, fix bugs, be as production-ready as possible.</li> </ul>"},{"location":"contribute/#pre-commit-hooks","title":"Pre-commit hooks","text":"<p>We use <code>pre-commit</code> to enforce code style and catch common issues with formmatting before commits.</p> <p>Before making changes, install the hooks with: <pre><code>pre-commit install\n</code></pre></p> <p>To run pre-commit hooks manually, use: <pre><code>pre-commit run --all-files\n</code></pre></p>"},{"location":"deployment/","title":"Deployment","text":""},{"location":"deployment/#dockerize-your-project","title":"Dockerize your project","text":"<p>Place Holder</p>"},{"location":"deployment/#small-scale-deployment-single-server-with-docker-compose","title":"Small-Scale Deployment: Single Server with Docker Compose","text":"<p>Placeholder for content</p>"},{"location":"deployment/#large-scale-deployment-kubernetes-k8s","title":"Large-Scale Deployment: Kubernetes (K8s)","text":"<p>Placeholder for content</p>"},{"location":"minicourse/","title":"Mini Course","text":"<p>we will go through some of the common concept related to web development that would help you better understand our tutorials.</p>"},{"location":"minicourse/#resource","title":"<code>Resource</code>","text":""},{"location":"minicourse/#any-identifiable-entity-that-can-be-accessed-via-a-url","title":"Any identifiable <code>entity</code> that can be accessed via a URL","text":"<p>Don't overthink it\u2014if you don\u2019t like the term <code>resource</code>, think of it as an <code>object</code>.</p>"},{"location":"minicourse/#entity","title":"<code>Entity</code>","text":"<p>Anyting that can be uniquely identified. for example</p> <pre><code>from dataclasses import dataclass, field\nfrom uuid import uuid4\n\nclass User:\n    user_id: str = field(default_factory=lambda: str(uuid4()))\n</code></pre> <p>Here, <code>User</code> is an entity as can be uniquely identified through <code>user_id</code>. meaing that, for any given two instances of <code>User</code>, <code>u1</code> and <code>u2</code>, if <code>u1.user_id</code> == <code>u2.user_id</code> then <code>u1 == u2</code>.</p>"},{"location":"minicourse/#uri","title":"<code>URI</code>","text":""},{"location":"minicourse/#uniform-resource-identifier","title":"Uniform Resource Identifier","text":"<p>A string that uniquely identifies a resource. a uri can be a url, a urn, or both. a url follows the format:</p> <p><code>protocol://domain/path?query#fragment</code></p> <p><code>#fragment</code> is commonly used for client-side navigation, usually you do not need it writing server side application.</p> <p>Example:</p> <p><code>https://myhost.com/users/lhl/orders?nums=3</code></p> <p>When you see a RESTful API with a URI like this, even without prior knowledge, you can infer that:</p> <ul> <li>It is a website hosted at <code>myhost.com</code>, using the <code>https</code> protocol.</li> <li>It is accessing a resource named <code>orders</code>, which belongs to a specific user <code>lhl</code>.</li> <li>It includes a query parameter, <code>nums</code>, with the value <code>3</code>.</li> </ul> <p><code>URL</code> (Uniform Resource Locator): A type of URI that not only identifies a resource but also provides a way to access it. URLs generally include a scheme (protocol), domain, path, query parameters, and optionally a fragment.</p>"},{"location":"minicourse/#asgi","title":"<code>ASGI</code>","text":"<p>ASGI refering to <code>Asynchronous Server Gateway Interface</code>, a protocol designed by <code>encode</code>.</p>"},{"location":"minicourse/#asgiapp","title":"<code>ASGIApp</code>","text":"<p>is an async callable with following signature.</p> <pre><code>class ASGIApp(Protocol):\n    async def __call__(self, scope, receive, send) -&gt; None: ...\n</code></pre> <p>where</p> <ul> <li><code>scope</code> is a mutable mapping, often a <code>dict</code>.</li> <li><code>receive</code> is an async callable that has no param and return a <code>message</code></li> <li><code>message</code> is also a mutable mapping, often <code>dict</code>.</li> <li><code>send</code>  is an async callable that receive a single param <code>message</code> and return <code>None</code></li> </ul> <p>Many components you see from <code>lihil</code> implementes <code>ASGIApp</code>, including</p> <ul> <li><code>Lihil</code></li> <li><code>Route</code></li> <li><code>Endpoint</code></li> <li><code>Response</code></li> </ul> <p>asgi middlewares are also <code>ASGIApp</code>.</p>"},{"location":"minicourse/#asgi-call-chain","title":"<code>ASGI Call Chain</code>","text":"<p><code>ASGIApp</code> are often chained together like a linked list(you might recognize this as the <code>chain of responsibility</code> pattern), where each call to the chain go through every node on the chain, for example, a ordinary call stack looks like this</p> <pre><code>flowchart LR\n    A[lihil.Lihil]\n    A --&gt; B[lihil.Route]\n    B --&gt; C[lihil.Endpoint]\n    C --&gt; D[Endpoint Function]\n</code></pre> <ul> <li> <p><code>Endpoint Function</code>  is the function you registered with <code>Route.{http method}</code>, such as <code>Route.get</code></p> </li> <li> <p>If you server lihil with an ASGI server such as uvicorn, <code>lihil.Lihil</code> will be called by uvicorn.</p> </li> </ul>"},{"location":"minicourse/#inversion-of-control-dependency-injection","title":"Inversion of Control &amp; Dependency Injection","text":""},{"location":"minicourse/#inversion-of-control","title":"Inversion of Control","text":"<p>Although the term <code>Inversion of Control</code> might sound exotic and fancy, and can be interpreted at different levels of software design, we only talk about one of its narrow sense here,</p> <p>Imagine you are writing a module that creates a user in database, you might have something like:</p> <pre><code>from sqlalchemy.ext.asyncio import create_engine, AsyncEngine\n\nclass Repo:\n    def __init__(self, engine: AsyncEngine):\n        self.engine = engine\n\n    async def add_user(self, user: User):\n        prepared_stmt = sle.prepare_add_user(user)\n        async with self.engine.connct() as conn:\n            await conn.execute(prepared_stmt)\n\nasync def create_user(user: User, repo: Repository):\n    await repo.add_user(user)\n\nasync def main():\n    engine = create_engine(url=url)\n    repo = Repo(engine)\n    user = User(name=\"user\")\n    await create_user(user, repo)\n</code></pre> <p>Here you are calling <code>create_user</code> from your <code>main</code> function inside a <code>main.py</code>, when you enter <code>python -m myproject.main</code>, function <code>main</code> and <code>create_user</code> gets called.</p> <p>Comparing with what would you do with lihil:</p> <pre><code>users_route = Route(\"/users\")\n\n@users_route.post\nasync def create_user(user: User, repo: Repository):\n    await repo.add_user(user)\n\nlhl = Lihil(routes=[user_route])\n</code></pre> <p>Notice here, instead of you actively calling <code>create_user</code> from your function, your function is called by lihil upon request arrival, and the dependencies of your <code>create_user</code> is managed and injected by lihil.</p> <p>This is an example of <code>Inversion of Control</code> and also one of the major reasons why a dedicated dependency injection tool <code>ididi</code> is used by lihil.</p>"},{"location":"minicourse/#compare-to-menually-building-dependency-inside-endpoint-function","title":"Compare to menually building dependency inside endpoint function","text":"<p>You might wonder why not building dependencies yourself inside the endpoint function.</p> <pre><code>@users_route.post\nasync def create_user(user: User):\n    engine = create_engine(url=url)\n    repo = Repo(engine)\n    await repo.add_user(user)\n</code></pre> <p>As we are not dynamically injecting <code>Repo</code> into <code>create_user</code>, we lose the benifits of</p> <ul> <li> <p>separation of interface and implementation:</p> <ol> <li>often we want to build engine differently depending on the environment we are deploying our app on, for example, you might want to increase the size of connection pool in prod.</li> <li>we won't be executing real query during test so we would need to mock the <code>Engine</code> object.</li> <li>if we create a new <code>AdvacnedEngine(Engine)</code> to cater our business need, we can't let <code>create_user</code> use it without modifying the code inside.</li> </ol> </li> <li> <p>lifetime control:     Dependencies have differernt lfietime, for example,     you might want to reuse a same <code>AsyncEngine</code> across different requests, but open a new <code>AsyncConnection</code> to handle each request.</p> </li> </ul>"},{"location":"testing/","title":"Testing","text":"<p>Lihil provide you two techniques for testing, <code>TestClient</code> and <code>LocalClient</code></p>"},{"location":"testing/#testclient","title":"<code>TestClient</code>","text":"<p><code>TestClient</code> provide you something that is close to manually constructing a request as client and post it to your server.</p> <p>For integration testing where each request should go through every part of your application, <code>TestClient</code> keep your test close to user behavior.</p> <p>Note that to use <code>TestClient</code>, you would need to install <code>httpx</code>.</p>"},{"location":"testing/#localclient","title":"<code>LocalClient</code>","text":"<p>if you want something less verbose and with smaller granularity, you can check out <code>LocalClient</code>,</p> <p><code>LocalClient</code> is more a test helper than a full-fledged request client as opposed to <code>TestClient</code>, you might use it to call <code>Lihil</code> instance, <code>Route</code>, and <code>Endpoint</code> locally in a fast and ergonomic manner.</p> <ul> <li>Test any function as if it were an endpoint:</li> </ul> <pre><code>from lihil import LocalClient\n\nasync def test_query_with_default():\n    async def func(name: tuple[str, ...]) -&gt; Empty:\n        assert name == (\"aloha\",)\n\n    lc = LocalClient()\n\n    resp = await lc.call_endpoint(lc.make_endpoint(func))\n    await resp.body()\n</code></pre> <ul> <li>Test a complex flow with LocalCLient</li> </ul> <pre><code>async def test_endpoint_login_and_validate(testroute: Route, lc: LocalClient):\n    from lihil.config import lhl_set_config\n\n    async def get_me(token: JWTAuth[UserProfile]) -&gt; Resp[Text, status.OK]:\n        assert token.user_id == \"1\" and token.user_name == \"2\"\n        return \"ok\"\n\n    async def login_get_token(login_form: OAuthLoginForm) -&gt; JWTAuth[UserProfile]:\n        return UserProfile(user_id=\"1\", user_name=\"2\")\n\n    testroute.get(auth_scheme=OAuth2PasswordFlow(token_url=\"token\"))(get_me)\n    testroute.post(login_get_token)\n    lhl_set_config(\n        app_config=AppConfig(\n            security=SecurityConfig(jwt_secret=\"mysecret\", jwt_algorithms=[\"HS256\"])\n        )\n    )\n    testroute.setup()\n\n    login_ep = testroute.get_endpoint(login_get_token)\n\n    res = await lc.submit_form(\n        login_ep, form_data={\"username\": \"user\", \"password\": \"test\"}\n    )\n\n    token_data = await res.json()\n\n    token_type, token = token_data[\"token_type\"], token_data[\"access_token\"]\n    token_type: str\n\n    lc.update_headers({\"Authorization\": f\"{token_type.capitalize()} {token}\"})\n\n    meep = testroute.get_endpoint(get_me)\n\n    res = await lc(meep)\n\n    assert res.status_code == 200\n    assert await res.text() == \"ok\"\n</code></pre>"},{"location":"tutorials/","title":"Tutorial","text":""},{"location":"tutorials/#basics","title":"Basics","text":""},{"location":"tutorials/#enpoint","title":"Enpoint","text":"<p>An <code>endpoint</code> is the most atomic ASGI component in <code>lihil</code>, registered under <code>Route</code> with <code>Route.{http method}</code>, such as <code>Route.get</code>. It defines how clients interact with the resource exposed by the <code>Route</code>.</p> <p>In the ASGI callchain the <code>endpoint</code> is typically at the end.</p> <p>Let's start with a function that creates a <code>User</code> in database.</p>"},{"location":"tutorials/#quick-start","title":"Quick Start:","text":"<p>Expose a random function as an endpoint</p> <p><code>app/users/api.py</code></p> <pre><code>from msgspec import Struct\nfrom sqlalchemy.ext.asyncio import AsyncEngine\nfrom .users.db import user_sql\n\nclass UserDB(UserData):\n    user_id: str\n\ndef get_engine() -&gt; AsyncEngine:\n    return AsyncEngine()\n\nasync def create_user(user: UserData, engine: AsyncEngine) -&gt; UserDB:\n    user_id = str(uuid4())\n    sql = user_sql(user=user, id_=user_id)\n    async with engine.begin() as conn:\n        await conn.execute(sql)\n    return UserDB.from_user(user, id=user_id)\n</code></pre> <p>To expose this function as an endpoint:</p> <pre><code>from lihil import Route\n\nusers_route = Route(\"/users\")\nusers_route.factory(get_engine)\nusers_route.post(create_user)\n</code></pre> <p>With just three lines, we:</p> <ol> <li>Create a Route with the path \"/users\".</li> <li>Register <code>AsyncEngine</code> as a dependency, using <code>get_engine</code> as its factory.</li> <li>Register create_user as the POST endpoint.</li> </ol> <p>You might also use python decorator syntax to register an endpoint</p> <pre><code>users_route = Route(\"/users\")\n\n@users_route.post\nasync def create_user(): ...\n</code></pre>"},{"location":"tutorials/#param-parsing","title":"Param Parsing","text":"<pre><code>from lihil import use, Ignore\nfrom typing import Annotated, NewType\nfrom sqlalchemy.ext.asyncio import AsyncConnection, AsyncEngine\n\nasync def get_conn(engine: AsyncEngine) -&gt; AsyncConnection:\n    async with engine.begin() as conn:\n        yield conn\n\nUserID = NewType(\"UserID\", str)\n\ndef user_id_factory() -&gt; UserID:\n    return UserID(str(uuid4()))\n\nasync def create_user(\n    user: UserData, user_id: UserID, conn: AsyncConnection\n) -&gt; Resp[UserDB, stauts.Created]:\n\n    sql = user_sql(user=user, id_=user_id)\n    await conn.execute(sql)\n    return UserDB.from_user(user, id=user_id)\n\nusers_route.factory(get_conn)\nusers_route.factory(user_id_factory, reuse=False)\n</code></pre> <p>Here,</p> <ol> <li><code>user_id</code> will be created by <code>user_id_factory</code> and return a uuid in str.</li> <li><code>conn</code> will be created by <code>get_conn</code> and return an instance of <code>AsyncConnection</code>, where the the connection will be returned to engine after request.</li> <li><code>UserDB</code> will be json-serialized, and return a response with content-type being <code>application/json</code>, status code being <code>201</code>.</li> </ol>"},{"location":"tutorials/#param-marks","title":"Param Marks","text":"<p>Explicitly declaring a parameter with a param mark tells Lihil to treat it as-is, without further analysis.</p> <ul> <li><code>Header[T, H]</code> for header param with type <code>T</code> and header key <code>H</code></li> <li><code>Cookie[T, C]</code> for cookie param with type <code>T</code> and cookie name <code>C</code></li> <li><code>Path[T]</code> for path param with type <code>T</code></li> <li><code>Query[T]</code> for query param with type <code>T</code></li> <li><code>Body[T]</code> for body param with type <code>T</code></li> <li><code>Form[T]</code> for body param with content type <code>multipart/from-data</code> and type [T]</li> <li><code>Use[T]</code> for dependency with type <code>T</code></li> </ul> <p><code>Header</code> and <code>Cookie</code> allows your to provide metadata for param parsing,</p> <p>Use <code>typing.Literal</code> to provide header/cookie name,</p> <pre><code>async def login(cred: Header[str, Literal[\"User-Credentials\"]], x_access_token: Header[str]) : ...\n</code></pre> <ul> <li> <p>Here param <code>cred</code> expects a header with key <code>User-Credentials</code>.</p> </li> <li> <p>If key not provided, The kebab case of param name is used, for example, here <code>x_access_token</code> expects a header with key <code>x-access-token</code></p> </li> </ul>"},{"location":"tutorials/#param-analysis-rules","title":"Param Analysis Rules","text":"<p>If a param is not declared with any param mark, the following rule would apply to parse it:</p> <ul> <li>If the param name appears in route path, it is interpreted as a path param.</li> <li>If the param type is a subclass of <code>msgspec.Struct</code>, it is interpreted as a body param.</li> <li> <p>If the param type is registered in the route graph, or is a lihil-primitive type, it will be interpered as a dependency and will be resolved by lihil</p> </li> <li> <p>Otherise, it is interpreted as a query param.</p> </li> </ul> <p>Example:</p> <pre><code>from lihil import Route, Payload, Use, EventBus\n\nuser_route = Route(\"/users/{user_id}\")\n\nclass UserUpdate(Payload): ...\nclass Engine: ...\nclass Cache: ...\n\nuser_route.factory(Cache)\n\n@user_route.put\nasync def update_user(user_id: str, engine: Use[Engine], cache: Cache, bus: EventBus):\n    return \"ok\"\n</code></pre> <p>In this example:</p> <ul> <li><code>user_id</code> appears in the route path, so it is a path param</li> <li><code>engine</code> is annotated with the <code>Use</code> mark, so it is a dependency</li> <li><code>cache</code> is registered in the user_route, so it is also a dependency</li> <li><code>bus</code> is a lihil-builtin type, it is therefore a dependency as well.</li> </ul> <p>Only <code>user_id</code> needs to be provided by the client request, rest will be resolved by lihil.</p> <p>Since return param is not declared, <code>\"ok\"</code> will be serialized as json <code>'\"ok\"'</code>, status code will be <code>200</code>.</p>"},{"location":"tutorials/#data-validation","title":"Data validation","text":"<p>lihil provide you data validation functionalities out of the box using msgspec.</p>"},{"location":"tutorials/#constraints","title":"Constraints","text":"<ul> <li>You might combine <code>typing.Annotated</code> and <code>msgspec.Meta</code> to put constraints on params,</li> </ul> <pre><code>all_users = Route(\"/users\")\n\n@all_users.get\nasync def get_users(numers: Annotated[int, msgspec.Meta(gt=0)]):\n    ...\n</code></pre> <p>Here <code>get_user</code> expects a query param <code>numers</code>, an integer with value greater than <code>0</code>.</p> <ul> <li>Constraints with structual data</li> </ul> <pre><code>from typing import Annotated\n\nfrom lihil import Payload\nfrom msgspec import Meta\n\nUnixName = Annotated[\n    str, Meta(min_length=1, max_length=32, pattern=\"^[a-z_][a-z0-9_-]*$\")\n]\n\nclass User(Payload):\n    name: UnixName\n    groups: Annotated[set[UnixName], Meta(max_length=16)] = set()\n    cpu_limit: Annotated[float, Meta(ge=0.1, le=8)] = 1\n    mem_limit: Annotated[int, Meta(ge=256, le=8192)] = 1024\n\n@all_users.post\nasync def create_user(user: User): ...\n</code></pre> <p>Here <code>create_user</code> expects a body param <code>user</code>, a structual data where each field has constraints.</p> <ul> <li>Constraints with supported types</li> </ul> <p>Checkout msgspec constraints for more details on specific constraints that you can set on different types.</p>"},{"location":"tutorials/#return-marks","title":"Return Marks","text":"<p>Often you would like to change the status code, or content type of your endpoint,  to do so, you can use one or a combination of several <code>return marks</code>. for example, to change stauts code:</p> <pre><code>from lihil import Resp, status\n\nasync def create_user(user: UserData, engine: Engine) -&gt; Resp[UserDB, status.Created]:\n    ...\n</code></pre> <p>Now <code>create_user</code> would return a status code <code>201</code>, instead of the default <code>200</code>.</p> <p>There are several other return marks you might want to use:</p> <ul> <li><code>Json[T]</code> for response with content-type <code>application/json</code></li> </ul> <p>Endpoints are assumed to return <code>Json[T]</code> by default, <code>async def f() -&gt; str</code> is the same as  <code>async def f() -&gt; Json[str]</code></p> <ul> <li><code>Stream[T]</code> for server sent event with content-type <code>text/event-stream</code></li> <li><code>Text</code> for response with content-type <code>text/plain</code></li> <li><code>HTML</code> for response with content-type <code>text/html</code></li> <li><code>Empty</code> for empty response</li> </ul> <p>You can use these return marks just like plain python return type hint</p> <pre><code>from lihil import Json\n\nasync def demo() -&gt; Json[list[int]]: ...\n</code></pre> <p>return marks have no runtime/typing effect outside of lihil, your type checker would treat <code>Json[T]</code> as <code>T</code>.</p>"},{"location":"tutorials/#response-with-status-code","title":"Response with status code","text":"<ul> <li><code>Resp[T, 200]</code> for response with status code <code>200</code>. where <code>T</code> can be anything json serializable, or another return mark.</li> </ul> <p>For instance, in the <code>create_user</code> example, we use <code>Resp[UserDB, status.Created]</code> to declare our return type, here <code>T</code> is <code>UserDB</code>.</p> <ul> <li>By default, the return convert is json-serialized, so that it is equiavlent to <code>Resp[Json[UserDB], status.Created]</code>.</li> <li>If you would like to return a response with content type <code>text/html</code>, you might use <code>HTML</code></li> </ul> <pre><code>async def hello() -&gt; HTML:\n    return \"&lt;p&gt;hello, world!&lt;/p&gt;\"\n</code></pre>"},{"location":"tutorials/#return-union","title":"Return Union","text":"<p>it is valid to return union of multiple types, they will be shown as <code>anyOf</code> schemas in the open api specification.</p> <pre><code>async def create_user() -&gt; User | TemporaryUser: ...\n</code></pre>"},{"location":"tutorials/#custom-encoderdecoder","title":"Custom Encoder/Decoder","text":"<p>You can also use your own customized encoder/decoder for request params and function return. To use them, annotate your param type with <code>CustomDecoder</code> and your return type with <code>CustomEncoder</code></p> <pre><code>from lihil.di import CustomEncoder, CustomDecoder\n\nuser_route = @Route(/users/{user_id})\n\nasync def get_user(\n    user_id: Annotated[str, CustomDecoder(decode_user_id)]\n) -&gt; Annotated[str, CustomEncoder(encode_user_id)]:\n    return user_id\n</code></pre> <pre><code>def decoder[T](param: str | bytes) -&gt; T: ...\n</code></pre> <ul> <li><code>decoder</code> should expect a single param with type either <code>str</code>, for non-body param, or <code>bytes</code>, for body param, and returns required param type, in the <code>decode_user_id</code> case, it is <code>str</code>.</li> </ul> <pre><code>def encoder[T](param: T) -&gt; bytes: ...\n</code></pre> <ul> <li><code>encoder</code> should expect a single param with any type that the endpoint function returns, in the <code>encode_user_id</code> case, it is <code>str</code>, and returns bytes.</li> </ul>"},{"location":"tutorials/#endpoint-properties","title":"EndPoint properties","text":"<ul> <li>Provide extra meta data of endpoint through route decorator.</li> </ul> <pre><code>@router.get(errors=[UserNotFoundError, UserInactiveError])\nasync get_user(user_id: str): ...\n</code></pre> <ul> <li>Endpoint can have these properties:</li> </ul> <pre><code>errors: Sequence[type[DetailBase[Any]]] | type[DetailBase[Any]]\n\"Errors that might be raised from the current `endpoint`. These will be treated as responses and displayed in OpenAPI documentation.\"\nin_schema: bool\n\"Whether to include this endpoint inside openapi docs\"\nto_thread: bool\n\"Whether this endpoint should be run wihtin a separate thread, only apply to sync function\"\nscoped: Literal[True] | None\n\"Whether current endpoint should be scoped\"\nauth_scheme: AuthBase | None\n\"Auth Scheme for access control\"\ntags: Sequence[str] | None\n\"OAS tag, endpoints with the same tag will be grouped together\"\n</code></pre> <pre><code>- `scoped`: if an endpoint requires any dependency that is an async context manager, or its factory returns an async generator, the endpoint would be scoped, and setting scoped to None won't change that, however, for an endpoint that is not scoped, setting `scoped=True` would make it scoped.\n</code></pre> <ul> <li>Provide a properties for every endpoint in the route:</li> </ul> <p>You might provide default properties when intialize a route,</p> <pre><code>from lihil.routing import Route, EndpointProps\n\ndefault_props = EndpointProps(errors=[UserNotFoundError, UserInactiveError])\nprop_route = Route(props=default_props)\n</code></pre> <ul> <li>Here <code>default_props</code> would be applied to every endpoint added to <code>prop_route</code>.</li> <li>endpoint properties provided via route decorator like <code>route.get</code> would override roperties provided by route.</li> </ul>"},{"location":"tutorials/#route","title":"Route","text":"<p>When you define a route, you expose a resource through a specific path that clients can request. you then add an <code>Endpoint</code> on the route to determin what clients can do with the resource.</p> <p>Take url <code>https://dontclickme.com/users</code> as an example, path <code>/users</code> would locate resource <code>users</code>.</p>"},{"location":"tutorials/#defining-an-route","title":"Defining an route","text":"<pre><code>from lihil import Route\n\nusers_route = Route(\"/users\")\n</code></pre> <p>If you have existing <code>lihil.Graph</code> and <code>lihil.MessageRegistry</code> that you would like to use, put then in the route constructor.</p> <p>This is useful if you keep dependencies and event listeners in separate files, example:</p> <pre><code>from project.users.deps import user_graph\nfrom project.users.listeners import user_eventregistry\n\nuser_route = Route(graph=uesr_graph, registry=user_eventregistry)\n</code></pre> <p>You can also add middlewares to a route if you want them to apply only to that specific route.</p> <pre><code>from starlette.middleware.cors import CORSMiddleware\nfrom starlette.middleware.httpsredirect import HTTPSRedirectMiddleware\n\nRoute(middlewares=[CORSMiddleware])\nroute.add_middleware(HTTPSRedirectMiddleware)\n</code></pre>"},{"location":"tutorials/#register-endpoint-to-an-route","title":"register endpoint to an route.","text":"<p>In previous dicussion, we expose <code>create_user</code> as an endpoint for <code>POST</code> request of <code>users_route</code>. we can also declare other http methods with similar syntax, this includes:</p> <ul> <li><code>GET</code></li> <li><code>POST</code></li> <li><code>HEAD</code></li> <li><code>OPTIONS</code></li> <li><code>TRACE</code></li> <li><code>PUT</code></li> <li><code>DELETE</code></li> <li><code>PATCH</code></li> <li><code>CONNECT</code></li> </ul> <p>This means that an route can have 0-9 endpoints.</p> <p>to expose a function for multiple http methods</p> <ul> <li> <p>apply multiple decorators to the function</p> </li> <li> <p>or, equivalently, use <code>Route.add_endpoint</code></p> </li> </ul> <pre><code>users_route.add_endpoint(\"GET\", \"POST\", ...,  create_user)\n</code></pre>"},{"location":"tutorials/#defining-an-sub-route","title":"Defining an sub-route","text":"<p>In previous discussion, we created a route for <code>users</code>, a collection of the user resource, to expose an specific user resource,</p> <pre><code>user_route = users_route.sub(\"{user_id}\")\n\n@user_route.get\nasync def get_user(user_id: str, limit: int = 1): ...\n</code></pre> <p>Here, we define a sub route of <code>users_route</code>, when we include an route into our <code>Lihil</code>, all of its sub-routes will also be included recursively.</p> <p>Route are unique to path, thus, you might call it constructor with same path multiple times.</p> <pre><code>@users_route.sub(\"{user_id}\").get\nasync def get_user(user_id: str, limit: int = 1): ...\n\n@users_route.sub(\"{user_id}\").put\nasync def update_user(data: UserUpdate): ...\n</code></pre> <p>here both <code>get_user</code> and <code>update_user</code> are under the same route.</p>"},{"location":"tutorials/#the-root-route","title":"The root route","text":"<p>an route with path <code>/</code> is the root route, if not provided, root route is created with <code>Lihil</code> by default, anything registered via <code>Lihil.{http method}</code> is the under the root route.</p>"},{"location":"tutorials/#websocket","title":"WebSocket","text":"<p>lihil supports the usage of websocket, you might use <code>WebSocketRoute.ws_handler</code> to register a function that handles websockets.</p> <pre><code>from lihil import WebSocketRoute, WebSocket, Ignore, use\n\nws_route = WebSocketRoute(\"web_socket/{session_id}\")\n\nasync def ws_factory(ws: WebSocket) -&gt; Ignore[AsyncResource[WebSocket]]:\n    await ws.accept()\n    yield ws\n    await ws.close()\n\n@ws_route.ws_handler\nasync def ws_handler(\n    ws: Annotated[WebSocket, use(ws_factory, reuse=False)],\n    session_id: str,\n    max_users: int,\n):\n    assert session_id == \"session123\" and max_users == 5\n    await ws.send_text(\"Hello, world!\")\n\nlhl = Lihil[None]()\nlhl.include_routes(ws_route)\n</code></pre> <p>Testing <pre><code>from lihil.vendors import TestClient # require httpx installed\n\nclient = TestClient(lhl)\nwith client:\n    with client.websocket_connect(\n        \"/web_socket/session123?max_users=5\"\n    ) as websocket:\n        data = websocket.receive_text()\n        assert data == \"Hello, world!\"\n</code></pre></p>"},{"location":"tutorials/#websocket-vs-http","title":"websocket vs http","text":"<ul> <li> <p>WebSocket handlers must be asynchronous \u2014 since communication is bidirectional and event-driven, the handler must use async def to support non-blocking interaction.</p> </li> <li> <p>WebSocket connections do not support request bodies in the same way as HTTP \u2014 there is no Body parameter during the handshake. All data is exchanged after the connection is established, typically through messages sent via the WebSocket protocol.</p> </li> <li> <p>WebSockets are stateful \u2014 unlike HTTP, which is stateless, a WebSocket connection persists, allowing continuous communication between the client and server. This enables maintaining per-connection state (e.g. user sessions, in-memory data).</p> </li> <li> <p>WebSockets use a different lifecycle \u2014 they begin with an HTTP handshake (usually a GET request), then upgrade the protocol. After that, communication is done over the WebSocket protocol, not HTTP.</p> </li> <li> <p>Standard request/response patterns do not apply \u2014 WebSockets are message-based and support real-time interaction, so traditional concepts like status codes, headers per message, or body parsing don\u2019t directly apply after the initial handshake.</p> </li> </ul>"},{"location":"tutorials/#middlewares","title":"Middlewares","text":"<p>Both <code>Lihil</code> and <code>Route</code> has <code>add_middleware</code> API that accept one, or a sequence of <code>MiddlewareFactory</code>.</p> <p>a <code>MiddlewareFactory</code> is a callable that receives one positional argument of type <code>ASGIApp</code> and returns a <code>ASGIApp</code>. for example:</p> <pre><code># This piece of code is for demonstration only.\n\ndef tracingmw_factory(next_app: ASGIApp) -&gt; ASGIApp:\n    async def tracemw(scope, receive, send):\n        scope[\"trace_id\"] = str(uuid.uuid4())\n        await next_app(scope, receive, send)\n    return trace_mw\n</code></pre> <p>lihil uses starlette internally, you can directly import middlewares from starlette, for example:</p> <pre><code>from starlette.middleware.cors import CORSSMiddleware\n\nlhl = Lihil(middlewares=[lambda app: CORSMiddleware(app, add_methods=\"*\")])\n</code></pre> <p>for complex middleware that require many external dependencies, you might to construct them inside lifespan.</p>"},{"location":"tutorials/#config-your-app","title":"Config Your App","text":"<p>There are several settings you can change to control the behavior of lihil,</p> <ol> <li> <p>config file, e.g: <code>pyproject.toml</code></p> <pre><code>lhl = Lihil(config_file=\"pyproject.toml\")\n</code></pre> <p>This will look for <code>tool.lihil</code> table in the <code>pyproject.toml</code> file extra/unkown keys will be forbidden to help prevent misconfiging</p> <p>Note: currently only toml file is supported</p> </li> <li> <p><code>AppConfig</code> instance</p> <pre><code>lhl = Lihil(app_config=AppConfig(version=\"0.1.1\"))\n</code></pre> <p>this is particularly useful if you want to inherit from AppConfig and extend it.</p> <pre><code>from lihil.config import AppConfig\n\nclass MyConfig(AppConfig):\n    app_name: str\n\nconfig = MyConfig.from_file(\"myconfig.toml\")\n</code></pre> </li> <li> <p>Command line arguments:</p> <pre><code>python app.py --oas.title \"New Title\" --is_prod true\n</code></pre> <ul> <li> <p>use <code>.</code> to express nested fields</p> </li> <li> <p>add <code>--help</code> to see available options</p> </li> </ul> </li> </ol> <p>You can access <code>AppConfig</code> anywhere in your app via <code>lihil.config.lhl_get_config</code></p> <pre><code>from lihil.config import lhl_get_config, AppConfig\n\napp_config: AppConfig = lhl_get_config()\n</code></pre>"},{"location":"tutorials/#error-hanlding","title":"Error Hanlding","text":"<ul> <li>use <code>route.get(errors=VioletsAreBlue)</code> to declare a endpoint response</li> </ul> <pre><code>class VioletsAreBlue(HTTPException[str]):\n    \"how about you?\"\n    __status__ = 418\n\n\n@lhl.post(errors=VioletsAreBlue)\nasync def roses_are_red():\n    raise VioletsAreBlue(\"I am a pythonista\")\n</code></pre> <ul> <li>use <code>lihil.problems.problem_solver</code> as decorator to register a error handler, error will be parsed as Problem Detail.</li> </ul> <pre><code>from lihil.problems import problem_solver\n\n# NOTE: you can use type union for exc, e.g. UserNotFound | status.NOT_FOUND\n@problem_solver\ndef handle_404(req: Request, exc: Literal[404]):\n    return Response(\"resource not found\", status_code=404)\n</code></pre> <p>A solver that handles a specific exception type (e.g., <code>UserNotFound</code>) takes precedence over a solver that handles the status code (e.g., <code>404</code>).</p>"},{"location":"tutorials/#exception-problem-mapping","title":"Exception-Problem mapping","text":"<p>lihil automatically generates a response and documentation based on your HTTPException, Here is the generated doc for the endpoint <code>roses_are_red</code></p> <p></p> <p>click url under <code>External documentation</code> tab</p> <p>we will see the detailed problem page</p> <p></p> <p>By default, every endpoint will have at least one response with code <code>422</code> for <code>InvalidRequestErrors</code>.</p> <p>Here is one example response of <code>InvalidRequestErrors</code>.</p> <pre><code>{\n  \"type_\": \"invalid-request-errors\",\n  \"status\": 422,\n  \"title\": \"Missing\",\n  \"detail\": [\n    {\n      \"type\": \"MissingRequestParam\",\n      \"location\": \"query\",\n      \"param\": \"q\",\n      \"message\": \"Param is Missing\"\n    },\n    {\n      \"type\": \"MissingRequestParam\",\n      \"location\": \"query\",\n      \"param\": \"r\",\n      \"message\": \"Param is Missing\"\n    }\n  ],\n  \"instance\": \"/users\"\n}\n</code></pre> <ul> <li>To alter the creation of the response, use <code>lihil.problems.problem_solver</code> to register your solver.</li> <li>To change the documentation, override <code>DetailBase.__json_example__</code> and <code>DetailBase.__problem_detail__</code>.</li> <li>To extend the error detail, provide typevar when inheriting <code>HTTPException[T]</code>.</li> </ul>"},{"location":"tutorials/#message-system","title":"Message System","text":"<p>Lihil has built-in support for both in-process message handling (Beta) and out-of-process message handling (implementing), it is recommended to use <code>EventBus</code> over <code>BackGroundTask</code> for event handling.</p> <p>There are three primitives for event:</p> <ol> <li>publish: asynchronous and blocking event handling that shares the same scope with caller.</li> <li>emit: non-blocking asynchrounous event hanlding, has its own scope.</li> <li>sink: a thin wrapper around external dependency for data persistence, such as message queue or database.</li> </ol> <pre><code>from lihil import Resp, Route, status\nfrom lihil.plugins.bus import Event, EventBus\nfrom lihil.plugins.testclient import LocalClient\n\n\nclass TodoCreated(Event):\n    name: str\n    content: str\n\n\nasync def listen_create(created: TodoCreated, ctx):\n    assert created.name\n    assert created.content\n\n\nasync def listen_twice(created: TodoCreated, ctx):\n    assert created.name\n    assert created.content\n\n\nbus_route = Route(\"/bus\", listeners=[listen_create, listen_twice])\n\n\n@bus_route.post\nasync def create_todo(name: str, content: str, bus: EventBus) -&gt; Resp[None, status.OK]:\n    await bus.publish(TodoCreated(name, content))\n</code></pre> <p>An event can have multiple event handlers, they will be called in sequence, config your <code>BusTerminal</code> with <code>publisher</code> then inject it to <code>Lihil</code>.</p> <ul> <li> <p>An event handler can have as many dependencies as you want, but it should at least contain two params: a sub type of <code>Event</code>, and a sub type of <code>MessageContext</code>.</p> </li> <li> <p>if a handler is reigstered with a parent event, it will listen to all of its sub event. for example,</p> </li> <li> <p>a handler that listens to <code>UserEvent</code>, will also be called when <code>UserCreated(UserEvent)</code>, <code>UserDeleted(UserEvent)</code> event is published/emitted.</p> </li> <li> <p>you can also publish event during event handling, to do so, declare one of your dependency as <code>EventBus</code>,</p> </li> </ul> <pre><code>async def listen_create(created: TodoCreated, _: Any, bus: EventBus):\n    if is_expired(created.created_at):\n        event = TodoExpired.from_event(created)\n        await bus.publish(event)\n</code></pre>"},{"location":"tutorials/#dependency-injection","title":"Dependency Injection","text":"<p>lihil uses ididi(https://lihil.cc/ididi) for dependency injection.</p>"},{"location":"tutorials/#usage-in-lihil","title":"Usage in lihil","text":""},{"location":"tutorials/#register-a-dependency-with-a-route","title":"register a dependency with a route","text":"<p>If a dependency is registered with any route, it will be available in every route included in <code>Lihil</code>.</p> <pre><code>class Engine: ...\ndef get_engine() -&gt; Engine: ...\n\nuser_route = Route(\"/user\")\nuser_route.add_nodes(get_engine) # register Engine as a dependency in user_route\n\norder_route = Route(\"/order\") # order will use `get_engine` to resolve `Engine` as well.\n\nlhl = Lihil(routes=[user_route, order_route])\n</code></pre> <ul> <li>use <code>Route.factory</code> to add a dependency, or <code>Route.add_nodes</code> to add many dependencies.</li> <li>It is recommended to register dependency where you use them, but you can register them to any route if you want.</li> <li>You might create a <code>ididi.Graph</code> first, register dependencies with it, then inject it into any route.</li> </ul>"},{"location":"tutorials/#declare-dependency-with-endpoint-signature","title":"Declare dependency with endpoint signature","text":"<p>If you would like to declare dependencies directly in your endpoint function: (as opposed to register with route)</p>"},{"location":"tutorials/#use-lihiluse-mark-to-declare-a-class-as-a-dependency","title":"Use <code>lihil.Use</code> mark to declare a class as a dependency.","text":"<pre><code>route = Route(\"/users\")\n\n@route.get\nasync def get_user(engine: Use[Engine]) : ...\n</code></pre>"},{"location":"tutorials/#use-typingannotatedt-usecallable-t-to-declare-a-factory-in-your-endpoint","title":"Use <code>typing.Annotated[T, use(Callable[..., T]])</code> to declare a factory in your endpoint","text":"<pre><code>from lihil import use\n\n@route.get\nasync def get_user(engine: Annotated[Engine, use(get_engine)]) : ...\n</code></pre>"},{"location":"tutorials/#use-ignore-in-return-annotation-to-declare-a-function-dependencies","title":"Use <code>Ignore</code> in return annotation to declare a function dependencies","text":"<p>You can create function as dependency by <code>Annotated[Any, use(your_function)]</code>. Do note that you will need to annotate your dependency function return type with <code>Ignore</code> like this</p> <pre><code>async def get_user(token: UserToken) -&gt; Ignore[User]: ...\n</code></pre>"},{"location":"tutorials/#tehcnical-details","title":"Tehcnical details","text":"<ul> <li> <p>If your factory function is a generator(function that contains <code>yield</code> keyword), it will be treated as <code>scoped</code>, meaning that it will be created before your endpoint function and destoried after. you can use this to achieve business purpose via clients that offer <code>atomic operation</code>, such as database connection.</p> </li> <li> <p>if your function is a sync generator, it will be solved within a separate thread.</p> </li> <li> <p>all graph will eventually merged into the main graph holding by <code>Lihil</code>, which means that, if you register a dependency with a factory in route <code>A</code>, the same factory can be used in every other route if it is required.</p> </li> </ul>"},{"location":"tutorials/#have-not-found-what-you-are-looking-for","title":"Have not found what you are looking for?","text":"<p>please let us know by posting in the discussion.</p>"},{"location":"archive/blueprint/","title":"BluePirnt","text":"framework RPS decay % asyncio 104,380 (- 100%) Uvicorn 46,426 (\u2193 55.5%) Starlette 35,433 (\u2193 23.7%) FastAPI 17,178 (\u2193 51.5%) <p>we can see uvicorn is a big bottleneck</p> <p>we can directly rewrite uvicorn using as much c as possible</p> <p>let data validation chain goes almost entirely in c</p> <p>socket -&gt; -&gt; uvloop -&gt; asyncio -&gt; http parser -&gt; msgspec -&gt; Request</p> <p>leave DI to python using ididi</p> <p>roughly</p> <p>asyncio -&gt; ASGI in c -&gt; lihil</p> <p>our expectation is for simple benchmark, we can achieve 60K RPS.</p>"},{"location":"archive/blueprint/#idea","title":"Idea","text":"<p>we might want to create a <code>licorne</code>(unicorn in french) before lihil that acts like a cython version of uvicorn</p> <p>Layered Infrastructure for High-Performance Integration and Logging</p>"},{"location":"archive/comparison/","title":"Comparison","text":"<p>we compare different level of abstractions on a web servers</p>"},{"location":"archive/comparison/#axum","title":"axum","text":"<pre><code>use axum::{\n    routing::post,\n    Json, Router,\n};\nuse serde_derive::{Deserialize, Serialize}; // Changed this line\nuse tokio::net::TcpListener;\n\n#[derive(Deserialize, Serialize)]\nstruct User {\n    id: i32,\n    name: String,\n    email: String,\n}\n\n#[tokio::main]\nasync fn main() {\n    // Build our application with a single POST route\n    let app = Router::new().route(\"/user\", post(create_user));\n\n    // Run our app with hyper, listening globally on port 8000\n    let listener = TcpListener::bind(\"0.0.0.0:8000\").await.unwrap();\n    println!(\"Server running on http://0.0.0.0:8000\");\n    axum::serve(listener, app).await.unwrap();\n}\n\n// Handler function that receives the JSON and returns the same data\nasync fn create_user(\n    Json(user): Json&lt;User&gt;,\n) -&gt; Json&lt;User&gt; {\n    Json(user)\n}\n</code></pre>"},{"location":"archive/comparison/#result","title":"Result","text":"<pre><code>Running 10s test @ http://localhost:8000/user\n  2 threads and 10 connections\n  Thread Stats   Avg      Stdev     Max   +/- Stdev\n    Latency   141.10us   28.93us 508.00us   71.74%\n    Req/Sec    34.24k   487.51    35.74k    76.73%\n  688132 requests in 10.10s, 101.72MB read\nRequests/sec:  68133.61\nTransfer/sec:     10.07MB\n</code></pre>"},{"location":"archive/comparison/#uvloop-asyncio-msgspec","title":"uvloop + asyncio + msgspec","text":"<pre><code>import asyncio\nfrom asyncio import StreamReader, StreamWriter\n\nimport uvloop\nfrom msgspec import Struct\nfrom msgspec.json import Decoder, Encoder\n\nencoder = Encoder()\ndecoder = Decoder(User)\n\nclass User(Struct):\n    id: int\n    name: str\n    email: str\n\ndef endpoint(data: bytes) -&gt; bytes:\n    user = decoder.decode(data)\n    body = encoder.encode(user)\n\n    # Adjust content length to reflect the actual size of the body\n    content_length = len(body)\n    response = (\n        f\"HTTP/1.1 200 OK\\r\\n\"\n        f\"Content-Length: {content_length}\\r\\n\"\n        f\"Content-Type: application/json\\r\\n\\r\\n\"\n    ).encode()\n\n    return response + body\n\nasync def handle_client(reader: StreamReader, writer: StreamWriter):\n    while True:\n        request_data = await reader.read(200)\n        if not request_data:\n            break\n        req = request_data.split(b\"\\r\\n\")\n        method, host, user_agent, *_, content_length, body = req\n        response = endpoint(body)  # Assuming body starts after headers\n\n        writer.write(response)\n        await writer.drain()\n    writer.close()\n\n\nasync def main():\n    port = 8000\n    print(f\"asyncio server started at {port}\")\n    server = await asyncio.start_server(handle_client, \"127.0.0.1\", port)\n\n    async with server:\n        await server.serve_forever()\n\n\nif __name__ == \"__main__\":\n    uvloop.run(main())\n</code></pre>"},{"location":"archive/comparison/#result_1","title":"Result","text":"<pre><code>Running 10s test @ http://localhost:8000\n  2 threads and 10 connections\n  Thread Stats   Avg      Stdev     Max   +/- Stdev\n    Latency    94.81us   37.10us   1.26ms   74.87%\n    Req/Sec    51.98k     1.85k   56.20k    76.73%\n  1044402 requests in 10.10s, 117.53MB read\nRequests/sec: 103412.80\nTransfer/sec:     11.64MB\n</code></pre>"},{"location":"archive/comparison/#comment","title":"Comment","text":"<p>uvloop(libuv) + asyncio is one of the fastest async IO lib across programming languages</p>"},{"location":"archive/comparison/#uvicorn-uvloop-https-msgspec","title":"uvicorn + uvloop + https + Msgspec","text":"<pre><code>from msgspec import Struct\nfrom msgspec.json import Decoder, Encoder\nfrom uvicorn._types import ASGIReceiveCallable, ASGISendCallable, Scope\n\n\nclass User(Struct):\n    id: int\n    name: str\n    email: str\n\n\nencoder = Encoder()\ndecoder = Decoder(User)\n\n\nasync def app(scope: Scope, receive: ASGIReceiveCallable, send: ASGISendCallable):\n    \"\"\"\n    ASGI application that handles user data.\n    \"\"\"\n    if scope[\"type\"] != \"http\":\n        return\n\n    # Receive the HTTP body\n    body: bytes = b\"\"\n    more_body = True\n\n    while more_body:\n        message = await receive()\n        body += message.get(\"body\", b\"\")\n        more_body = message.get(\"more_body\", False)\n\n    user = decoder.decode(body)\n    response_body = encoder.encode(user)\n    content_lengh = str(len(response_body)).encode()\n\n    # Send response headers\n    await send(\n        {\n            \"type\": \"http.response.start\",\n            \"status\": 200,\n            \"headers\": [\n                [b\"content-type\", b\"application/json\"],\n                [b\"content-length\", content_lengh],\n            ],\n        }\n    )\n\n    # Send response body\n    await send(\n        {\n            \"type\": \"http.response.body\",\n            \"body\": response_body,\n        }\n    )\n</code></pre>"},{"location":"archive/comparison/#result_2","title":"Result","text":"<pre><code>Running 10s test @ http://localhost:8000\n  2 threads and 10 connections\n  Thread Stats   Avg      Stdev     Max   +/- Stdev\n    Latency   213.23us   75.43us   1.76ms   67.23%\n    Req/Sec    23.23k     1.95k   27.82k    72.28%\n  466856 requests in 10.10s, 76.58MB read\nRequests/sec:  46224.84\nTransfer/sec:      7.58MB\n</code></pre>"},{"location":"archive/comparison/#cli-command-used-to-run-apps","title":"CLI Command used to run apps","text":"<pre><code>python3 -m uvicorn\n--interface asgi3\n--no-access-log\n--log-level \"warning\"\n--http httptools server:app\n</code></pre>"},{"location":"archive/comparison/#starlette-msgspec","title":"Starlette + Msgspec","text":"<pre><code>from msgspec import Struct\nfrom msgspec.json import Decoder, Encoder\nfrom starlette.applications import Starlette\nfrom starlette.requests import Request\nfrom starlette.responses import Response\n\nencoder = Encoder()\n\n\nclass User(Struct):\n    id: int\n    name: str\n    email: str\n\n\ndecoder = Decoder(User)\n\n\nasync def msgspec_user(r: Request) -&gt; Response:\n    content = await r.body()\n    user = decoder.decode(content)\n    u = User(id=user.id, name=user.name, email=user.email)\n    return Response(content=encoder.encode(u))\n\n\napp = Starlette()\napp.add_route(\"/fast/u\", msgspec_user, methods=[\"POST\"])\n</code></pre>"},{"location":"archive/comparison/#result_3","title":"Result","text":"<pre><code>Running 10s test @ http://localhost:8000/fast/u\n  2 threads and 10 connections\n  Thread Stats   Avg      Stdev     Max   +/- Stdev\n    Latency   277.15us   95.49us   2.40ms   67.26%\n    Req/Sec    17.90k     5.13k   24.53k    45.05%\n  359840 requests in 10.10s, 48.04MB read\nRequests/sec:  35628.38\nTransfer/sec:      4.76MB\n</code></pre>"},{"location":"archive/comparison/#fastapi-pydantic","title":"FastAPI + Pydantic","text":"<pre><code>from fastapi import FastAPI\nfrom pydantic import BaseModel\n\n\nclass User(BaseModel):\n    id: int\n    name: str\n    email: str\n\n\nasync def pydantic_user(user: User) -&gt; User:\n    u = User(id=user.id, name=user.name, email=user.email)\n    return u\n\n\napp = FastAPI()\napp.add_api_route(\"/fast/u\", pydantic_user, methods=[\"POST\"])\n</code></pre>"},{"location":"archive/comparison/#result_4","title":"Result","text":"<pre><code>Running 10s test @ http://localhost:8000/fast/u\n  2 threads and 10 connections\n  Thread Stats   Avg      Stdev     Max   +/- Stdev\n    Latency   578.80us  196.91us   3.53ms   69.46%\n    Req/Sec     8.65k     0.98k    9.96k    52.50%\n  172103 requests in 10.00s, 28.23MB read\nRequests/sec:  17209.98\nTransfer/sec:      2.82MB\n</code></pre>"},{"location":"archive/comparison/#starlette-pydantic","title":"Starlette + Pydantic","text":"<pre><code>from starlette.applications import Starlette\nfrom starlette.requests import Request\nfrom starlette.responses import Response\nfrom pydantic import BaseModel\n\n\nclass User(BaseModel):\n    id: int\n    name: str\n    email: str\n\n\n\nasync def msgspec_user(r: Request) -&gt; Response:\n    content = await r.body()\n    user = User.model_validate_json(content)\n    u = User(id=user.id, name=user.name, email=user.email)\n    return Response(content=User.__pydantic_serializer__.to_json(u))\n\n\napp = Starlette()\napp.add_route(\"/fast/u\", msgspec_user, methods=[\"POST\"])\n</code></pre>"},{"location":"archive/comparison/#result_5","title":"Result","text":"<pre><code>Running 10s test @ http://localhost:8000/fast/u\n  2 threads and 10 connections\n  Thread Stats   Avg      Stdev     Max   +/- Stdev\n    Latency   309.95us  107.56us   2.10ms   70.69%\n    Req/Sec    16.07k     2.38k   19.20k    54.95%\n  323186 requests in 10.10s, 43.15MB read\nRequests/sec:  31998.79\nTransfer/sec:      4.27MB\n</code></pre> <p>Bonus</p>"},{"location":"archive/comparison/#hardcoded-asyncio","title":"Hardcoded asyncio","text":"<pre><code>import asyncio\n\nimport uvloop\n\n\ndef endpoint():\n    response = \"HTTP/1.1 200 OK\\r\\nContent-Length: 12\\r\\n\\r\\nHello, World\"\n    return response\n\n\nasync def handle_client(reader, writer):\n    while True:\n        request_data = await reader.read(1000)\n        if not request_data:\n            break\n\n        response = endpoint()\n        writer.write(response.encode())\n        await writer.drain()\n\n    writer.close()\n\n\nasync def main():\n    server = await asyncio.start_server(handle_client, \"127.0.0.1\", 8000)\n\n    async with server:\n        await server.serve_forever()\n\n\nif __name__ == \"__main__\":\n    uvloop.run(main())\n</code></pre> <pre><code>Running 10s test @ http://localhost:8000\n  2 threads and 10 connections\n  Thread Stats   Avg      Stdev     Max   +/- Stdev\n    Latency    84.73us   33.54us   1.05ms   68.02%\n    Req/Sec    57.58k     2.75k   61.56k    61.88%\n  1157219 requests in 10.10s, 56.28MB read\nRequests/sec: 114584.34\nTransfer/sec:      5.57MB\n</code></pre>"},{"location":"archive/comparison/#fastapi-architecture-breakdown-with-rps-metrics","title":"FastAPI Architecture breakdown with RPS metrics","text":"<pre><code>flowchart TD\n    subgraph Python_Framework\n        FastAPI[\"FastAPI (17,210 RPS): Modern, fast web framework\"]\n        Starlette[\"Starlette (35,628 RPS): ASGI framework/toolkit\"]\n        Uvicorn[\"Uvicorn(46,225 RPS): ASGI web server\"]\n    end\n\n    subgraph Low_Level_Components\n        httptools[\"httptools HTTP parser based on llhttp\"]\n        uvloop[\"uvloop(103,412 RPS): Fast event loop based on libuv\"]\n        asyncio[\"asyncio Python async framework\"]\n    end\n\n    subgraph C_Libraries\n        llhttp[\"llhttp C-based HTTP parser\"]\n        libuv[\"libuv C-based async I/O\"]\n    end\n\n    FastAPI --&gt; Starlette\n    Starlette --&gt; Uvicorn\n    Uvicorn --&gt; httptools\n    httptools --&gt; llhttp\n    Uvicorn --&gt; asyncio\n    asyncio --&gt; uvloop\n    uvloop --&gt; libuv\n\n    style Python_Framework fill:#e1f3ff\n    style Low_Level_Components fill:#fff3e1\n    style C_Libraries fill:#ffe1e1\n</code></pre>"},{"location":"archive/comparison/#axum-architecture-breakdown","title":"Axum Architecture breakdown","text":"<pre><code>flowchart TD\n    subgraph Rust_Framework\n        Axum[\"Axum: Ergonomic and modular web framework\"]\n        Tower[\"Tower: Service/middleware abstraction\"]\n        Hyper[\"Hyper: Fast HTTP implementation\"]\n    end\n\n    subgraph Low_Level_Components\n        TokioHttp[\"h2/http: Low-level HTTP types\"]\n        Mio[\"Mio: Cross-platform IO\"]\n    end\n\n    subgraph Runtime\n        Tokio[\"Tokio: Async runtime and utilities\"]\n    end\n\n    Axum --&gt; Tower\n    Tower --&gt; Hyper\n    Hyper --&gt; TokioHttp\n    Hyper --&gt; Tokio\n    Tokio --&gt; Mio\n\n    style Rust_Framework fill:#ffe1e1\n    style Low_Level_Components fill:#fff3e1\n    style Runtime fill:#e1f3ff\n</code></pre>"},{"location":"archive/middleware/","title":"Middleware","text":"<p>Lihil is ASGI-compatible, meaning that you can apply asgi middlewares to lihil, including those from third-party libraries, such as starlette.</p> <pre><code>from lihil import Route\nfrom lihil.interface import ASGIApp\n\ntype ASGIApp = Callable[[Scope, Receive, Send], Awaitable[None]]\n\n\nroute = Route()\nroute.add_middleware(lambda app: CORSMiddleware(app, allow_origin=\"*\"))\n</code></pre> <p>Middleware is injectable, meaning that if your middleware factory requires dependencies, they will be injected dynamically</p>"},{"location":"archive/simple_bench/","title":"Minibench","text":"<p>This is a benchmark shows the performance difference between lihil and other ASGI frameworks.</p> <p>Note that this benchmark will be updated frequently and test results are subject to change.</p>"},{"location":"archive/simple_bench/#context","title":"Context","text":""},{"location":"archive/simple_bench/#hardware","title":"Hardware","text":"<p>AMD Ryzen 9 7950X 16-Core Processor  4.50 GHz</p> <p>RAM 64.0 GB (63.1 GB usable)</p> <p>internet ethernet controller i225v</p>"},{"location":"archive/simple_bench/#os","title":"OS","text":"<ul> <li>Ubuntu 20.04.6 LTS</li> </ul>"},{"location":"archive/simple_bench/#packages","title":"packages","text":"<ul> <li>python == 3.12</li> <li>uvloop==0.21.0</li> <li>uvicorn==0.34.0</li> <li>lihil==0.1.3</li> <li>fastapi==0.115.8</li> </ul>"},{"location":"archive/simple_bench/#parsing-path-query-body-and-inject-dependency","title":"Parsing path, query, body and inject dependency","text":""},{"location":"archive/simple_bench/#lihil-v013","title":"lihil v0.1.3","text":"<pre><code>profile_route = Route(\"profile/{pid}\")\n\n\nclass Engine: ...\n\n\ndef get_engine() -&gt; Engine:\n    return Engine()\n\n\nprofile_route.factory(get_engine)\n\n\n@profile_route.post\nasync def profile(pid: str, q: int, user: User, engine: Engine) -&gt; User:\n    return User(id=user.id, name=user.name, email=user.email)\n\nlhl = Lihil()\nlhl.include_routes(profile_route)\n\nif __name__ == \"__main__\":\n    uvicorn.run(lhl, access_log=None, log_level=\"warning\")\n</code></pre>"},{"location":"archive/simple_bench/#result","title":"result","text":"<pre><code>wrk -t4 -c64 'http://localhost:8000/profile/p?q=5' -s scripts/post.lua\nRunning 10s test @ http://localhost:8000/profile/p?q=5\n  4 threads and 64 connections\n  Thread Stats   Avg      Stdev     Max   +/- Stdev\n    Latency     1.72ms  319.52us  21.22ms   95.77%\n    Req/Sec     9.32k   474.64    14.12k    91.00%\n  371254 requests in 10.05s, 54.52MB read\nRequests/sec:  36955.88\nTransfer/sec:      5.43MB\n</code></pre>"},{"location":"archive/simple_bench/#fastapi-v01158","title":"FastAPI v0.115.8","text":"<pre><code>from fastapi import Fastapi\n\nclass Engine: ...\n\ndef get_engine() -&gt; Engine:\n    return Engine()\n\nprofile_route = APIRouter()\n\n@profile_route.post(\"/profile/{pid}\")\nasync def profile(\n    pid: str, q: int, user: User, engine: Annotated[Engine, Depends(get_engine)]\n) -&gt; User:\n    return User(id=user.id, name=user.name, email=user.email)\n\n\napp = FastAPI()\napp.include_router(profile_route)\n\nif __name__ == \"__main__\":\n    uvicorn.run(app, access_log=None, log_level=\"warning\")\n</code></pre>"},{"location":"archive/simple_bench/#result_1","title":"result","text":"<pre><code>Running 10s test @ http://localhost:8000/profile/p?q=5\n  4 threads and 64 connections\n  Thread Stats   Avg      Stdev     Max   +/- Stdev\n    Latency     4.98ms    1.11ms  62.49ms   93.44%\n    Req/Sec     3.23k   243.30     5.96k    94.50%\n  128792 requests in 10.07s, 21.13MB read\nRequests/sec:  12783.44\nTransfer/sec:      2.10MB\n</code></pre>"},{"location":"design/structure/","title":"Structure","text":"<pre><code>project/\n    source/\n        msgs.py\n        api.py\n    apps/\n        users/\n            repo.py # user repo\n            model.py # user models\n            user.py # user services\n        auth/\n            ...\n    sink/\n        event_sink.py\n        remote_sink.py\n    adapters/\n        mq.py\n        db.py\n</code></pre>"}]}